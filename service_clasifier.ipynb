{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30b3f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch #torchvision torchaudio\n",
    "#!pip install transformers\n",
    "#!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06ba4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#Roman Number IV A into IVA\n",
    "\n",
    "def standardize_roman_numerals(text):\n",
    "  if not isinstance(text, str):\n",
    "    return text  # or you can return a default value like '' if you want to replace non-strings\n",
    "  roman_pattern = re.compile(r\"(?<=\\b)(IV|IX|XL|XC|CD|CM|I{1,3}|V|X{1,3}|L|C{1,3}|D|M{1,3})([-\\s])([A-Za-z])(?=\\b)\")\n",
    "  return roman_pattern.sub(r\"\\1\\3\", text)\n",
    "\n",
    "#Letter PS 1 into PS1\n",
    "\n",
    "def standardize_ps(text):\n",
    "  if not isinstance(text, str):\n",
    "    return text  # or you can return a default value like '' if you want to replace non-strings\n",
    "  regex_pattern = r'(PS)([\\s-]*)(\\d+)'\n",
    "  return re.sub(regex_pattern, r'\\1\\3', text)\n",
    "\n",
    "#Roman dictionary\n",
    "roman_numerals = {\n",
    "    'I': 1, 'II': 2, 'III': 3, 'IV': 4, 'V': 5,\n",
    "    'VI': 6, 'VII': 7, 'VIII': 8, 'IX': 9, 'X': 10,\n",
    "    'XI': 11, 'XII': 12, 'XIII': 13, 'XIV': 14, 'XV': 15,\n",
    "    'XVI': 16, 'XVII': 17, 'XVIII': 18, 'XIX': 19, 'XX': 20\n",
    "  }\n",
    "\n",
    "\n",
    "def roman_to_number(text) :\n",
    "  return roman_numerals.get(text.upper(), text)\n",
    "\n",
    "# Standardize \"tipe\" or \"type\" to \"type\"\n",
    "\n",
    "def standardize_typetest(text):\n",
    "\n",
    "  def replace_with_standardized(match):\n",
    "    type_word = match.group(1)\n",
    "    number = match.group(2).replace('-', '').replace(' ', '')\n",
    "    if number.upper() in roman_numerals:\n",
    "      number = roman_to_number(number.upper())\n",
    "    return f'{type_word}{number}'\n",
    "\n",
    "  text = re.sub(r'\\b(tipe|type)\\b[\\s-]*(\\b(?:I{1,3}|IV|V|VI{0,3}|IX|X{1,3}|XI{0,3}|IX|XX|[0-9]+)\\b)', replace_with_standardized, text, flags=re.IGNORECASE)\n",
    "  return text\n",
    "\n",
    "def normalize_text(text):\n",
    "  if not isinstance(text, str):\n",
    "    return text  # or you can return a default value like '' if you want to replace non-strings\n",
    "\n",
    "  # Standardize Covid variations to 'Covid19'\n",
    "  text = re.sub(r'\\bcovid\\b', 'Covid', text, flags=re.IGNORECASE)\n",
    "  text = re.sub(r'Covid[\\s-]*19', 'Covid19', text, flags=re.IGNORECASE)\n",
    "  text = re.sub(r'Covid(?!\\d+)', 'Covid19', text, flags=re.IGNORECASE)\n",
    "\n",
    "  # Replace CKR and its variants with 'cidera kepala ringan'\n",
    "  text = re.sub(r'\\bckr\\b', 'cidera kepala ringan', text, flags=re.IGNORECASE)\n",
    "\n",
    "  # Replace CKR and its variants with 'cidera kepala ringan'\n",
    "  text = re.sub(r'\\bcks\\b', 'cidera kepala ringan', text, flags=re.IGNORECASE)\n",
    "\n",
    "  # Replace stg, stage and its variants with 'stage'\n",
    "  text = re.sub(r'\\bstg\\b|\\bstage\\b', 'stage', text, flags=re.IGNORECASE)\n",
    "\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8894d39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Define the model class (ensure it matches your training code)\n",
    "class StackedGRUModel(nn.Module):\n",
    "    def __init__(self, bert_model_name, hidden_dim, n_layers, num_classes, bidirectional=True, dropout=0.2):\n",
    "        super(StackedGRUModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=self.bert.config.hidden_size,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=n_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if n_layers > 1 else 0\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        embedded = bert_outputs.last_hidden_state\n",
    "        embedded = self.dropout(embedded)\n",
    "        gru_out, _ = self.gru(embedded)\n",
    "        gru_out = self.dropout(gru_out)\n",
    "        logits = self.fc(gru_out[:, -1, :])\n",
    "        probs = self.softmax(logits)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d478d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the model\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    bert_model_name = 'bert-base-uncased'\n",
    "    hidden_dim = 256\n",
    "    n_layers = 2\n",
    "    num_classes = 10\n",
    "    dropout = 0.2\n",
    "    bidirectional = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = StackedGRUModel(bert_model_name, hidden_dim, n_layers, num_classes, bidirectional, dropout).to(device)\n",
    "    save_path = 'bert_bigru_model.pth'\n",
    "    model.load_state_dict(torch.load(save_path, map_location=device))\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    return model, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1c41333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the saved LabelEncoder\n",
    "import pickle\n",
    "\n",
    "def load_label_encoder():\n",
    "    \n",
    "    # Path to the saved LabelEncoder\n",
    "    filepath = 'label_encoder.pkl'  # Adjust the path as needed\n",
    "\n",
    "\n",
    "    with open(filepath, 'rb') as f:\n",
    "        label_encoder = pickle.load(f)\n",
    "    return label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d856aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit app\n",
    "st.title(\"Klasifikasi Text dengan BERT and BiGRU\")\n",
    "st.write(\"Masukkan text untuk klasifikasi:\")\n",
    "\n",
    "# Initialize session state\n",
    "if 'model' not in st.session_state:\n",
    "    with st.spinner('Loading model...'):\n",
    "        st.session_state.model, st.session_state.device = load_model()\n",
    "        st.session_state.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') \n",
    "        st.session_state.label_encoder = load_label_encoder()   \n",
    "\n",
    "text_input = st.text_area(\"Diagnosa primer\", \"Contoh text .\")\n",
    "\n",
    "st.write(\"Kode ICD 10: [A16.2, D38.1, I25.1, K30, Z03.1, K01.1]\")\n",
    "st.write(\" NN = [J47,S06.0, U07.1, C34.9]\")\n",
    "\n",
    "if st.button(\"Classify\"):\n",
    "    if text_input:\n",
    "        try:\n",
    "            # Preprocess the text\n",
    "            preprocess = text_input\n",
    "            preprocess = standardize_roman_numerals(preprocess)\n",
    "            preprocess = standardize_ps(preprocess)\n",
    "            preprocess = normalize_text(preprocess)\n",
    "            preprocess = standardize_typetest(preprocess)\n",
    "            text_input = preprocess        \n",
    "\n",
    "            inputs = st.session_state.tokenizer(text_input, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "            input_ids = inputs['input_ids'].to(st.session_state.device)\n",
    "            attention_mask = inputs['attention_mask'].to(st.session_state.device)\n",
    "\n",
    "            if st.session_state.model is not None:\n",
    "                with torch.no_grad():\n",
    "                    outputs = st.session_state.model(input_ids, attention_mask)\n",
    "                    predicted_class = torch.argmax(outputs, dim=1).cpu().numpy()  \n",
    "                    predicted_label = st.session_state.label_encoder.inverse_transform(predicted_class)[0] \n",
    "                st.write(f\"Prediksi ICD 10: {predicted_label}\")\n",
    "            else:\n",
    "                st.write(\"Model tidak dapat dipanggil.\")\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error saat mengklasifikasikan: {e}\")\n",
    "    else:\n",
    "        st.write(\"Silahkan masukkan text untuk prediksi klasifikasi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156d8f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
